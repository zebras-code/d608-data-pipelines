# D608 Data Pipelines Project â€“ Airflow + Redshift

This project is part of the WGU D608 course. It demonstrates a complete ETL pipeline built with Apache Airflow that extracts JSON data from AWS S3, stages it in Amazon Redshift, transforms it into a star schema, and performs automated data quality checks.

---

## ğŸ“ Project Structure

```
dags/
  â””â”€â”€ final_project.py
plugins/
  â””â”€â”€ operators/
      â”œâ”€â”€ __init__.py
      â”œâ”€â”€ stage_redshift.py
      â”œâ”€â”€ load_fact.py
      â”œâ”€â”€ load_dimension.py
      â””â”€â”€ data_quality.py
helpers/
  â””â”€â”€ sql_queries.py
```

---

## âš™ï¸ Technologies Used
- Apache Airflow
- Amazon Redshift
- Amazon S3
- Python (custom operators)
- SQL (Redshift dialect)

---

## ğŸ” Workflow Steps

1. `Begin_execution` â€“ Starts the DAG
2. `Stage_events`, `Stage_songs` â€“ Loads raw JSON from S3 to Redshift
3. `Load_songplays_fact_table` â€“ Inserts data into fact table using SQL
4. `Load_user/song/artist/time_dim_table` â€“ Loads dimension tables
5. `Run_data_quality_checks` â€“ Verifies row counts in key tables
6. `Stop_execution` â€“ Ends the DAG

---

## ğŸ”Œ Airflow Connections

Ensure the following Airflow connections are configured:

| ID               | Type         | Notes                        |
|------------------|--------------|-------------------------------|
| `aws_credentials` | Amazon Web Services | For accessing S3              |
| `redshift`        | Postgres     | Points to your Redshift cluster |

Also set this **Airflow Variable**:
```bash
s3_bucket = zainab-dend-buckets
```

---

## ğŸ§ª Data Quality Checks
The DAG includes a custom operator that runs SQL checks such as:
```sql
SELECT COUNT(*) FROM users
SELECT COUNT(*) FROM songs
```
If results do not match expected values, the DAG will fail.

---

## ğŸ“„ Example SQL Logic

SQL logic is stored in `sql_queries.py`:
```sql
SELECT DISTINCT userid, firstname, lastname FROM staging_events WHERE page='NextSong';
```

---

## âœ… Rubric Coverage
- [x] Custom operators with parameters
- [x] Dynamic S3 â†’ Redshift COPY logic
- [x] Configurable truncate vs append mode
- [x] Data quality tests with error handling
- [x] Fully defined DAG with dependencies

---

## Author
Zainab Abbas  
WGU D608: Data Pipelines
